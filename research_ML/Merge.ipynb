{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ZJjCIgpv46gg",
   "metadata": {
    "id": "ZJjCIgpv46gg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/yuyang/.local/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (4.29.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yuyang/.local/lib/python3.9/site-packages (from matplotlib) (1.22.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/yuyang/miniconda3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yuyang/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e46c65",
   "metadata": {
    "id": "a8e46c65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 12:40:17.875609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Embedding, Bidirectional, TimeDistributed, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12ce0d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e12ce0d3",
    "outputId": "d561f901-6d86-4f8f-99a8-d052b1ae5d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   counts                  smiles property  value\n",
      "0       0             [*]CC([*])C      Eat  -5.14\n",
      "1       1             [*]CC([*])F      Eat  -5.18\n",
      "2       2          [*]CC([*])(F)F      Eat  -5.21\n",
      "3       3       [*]C(F)C([*])(F)F      Eat  -5.11\n",
      "4       4  [*]CCC(F)(F)C([*])(F)F      Eat  -5.21\n"
     ]
    }
   ],
   "source": [
    "# importing data\n",
    "df = pd.read_csv('data.csv')\n",
    "  \n",
    "# head of the data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1ff196",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c1ff196",
    "outputId": "57c86248-63aa-4da0-93ab-fd0b1b60ae74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                      [*]CC([*])C\n",
      "1                                      [*]CC([*])F\n",
      "2                                   [*]CC([*])(F)F\n",
      "3                                [*]C(F)C([*])(F)F\n",
      "4                           [*]CCC(F)(F)C([*])(F)F\n",
      "                           ...                    \n",
      "6260    [*]C(F)(F)C(F)(F)C(S1)=CC=C1C(S2)=CC=C2[*]\n",
      "6261                    [*]C(F)(F)C(F)(F)C(=O)O[*]\n",
      "6262          [*]C(F)(F)C(=O)C(F)(F)C(S1)=CC=C1[*]\n",
      "6263        [*]C(F)(F)C(=O)C(F)(F)C(C=C1)=CC=C1[*]\n",
      "6264                        [*]C(F)(F)OC(F)(F)O[*]\n",
      "Name: smiles, Length: 6265, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles = df['smiles']\n",
    "print(smiles)\n",
    "type(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6bcaad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c6bcaad",
    "outputId": "c596b6b6-661b-4420-b246-7f52952ee270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 47\n"
     ]
    }
   ],
   "source": [
    "# Find the number of missing values\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(\"Number of missing values:\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784576a4",
   "metadata": {
    "id": "784576a4"
   },
   "outputs": [],
   "source": [
    "# Delete the missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fbc23b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fbc23b",
    "outputId": "cc208d24-63df-4b45-931a-97b5771d9362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more missing values in the dataset.\n",
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are no more missing values\n",
    "assert df.isnull().sum().sum() == 0\n",
    "\n",
    "missing_values = df.isnull().sum().sum()\n",
    "\n",
    "print(\"No more missing values in the dataset.\")\n",
    "print(\"Number of missing values:\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bb91de5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bb91de5",
    "outputId": "eaa4bcec-cf4b-464a-82df-faf288d5ceae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      -5.14\n",
      "1      -5.18\n",
      "2      -5.21\n",
      "3      -5.11\n",
      "4      -5.21\n",
      "        ... \n",
      "6260    4.36\n",
      "6261    3.31\n",
      "6262    4.05\n",
      "6263    3.57\n",
      "6264    3.80\n",
      "Name: value, Length: 6218, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df['value']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e981624",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e981624",
    "outputId": "335ad515-430a-47a8-ab3e-524bf2601fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df : \n",
      "      counts                                  smiles property    value\n",
      "4775    4775   [*]c1ccc(-c2nc3cc4nc([*])oc4cc3o2)cc1      Eea   3.0398\n",
      "962      962               [*]CC([*])C(=O)OCCCSCCC#N      Egc   5.4080\n",
      "783      783            [*]C(=O)c1ccc(N([*])CCCC)cc1       Xc  71.5600\n",
      "5768    5768  [*]NC(=O)C(C=C1)=CC=C1C(C=C2)=CC=C2[*]       nc   2.0808\n",
      "937      937                   [*]CC([*])(C)C(=O)OCC      Egc   6.4148\n",
      "test_df : \n",
      "      counts                                   smiles property   value\n",
      "854      854                   [*]CC([*])c1ccc(C)cc1C      Egc  4.8585\n",
      "3165    3165                         [*]CCCNC(=O)O[*]      Egc  6.2603\n",
      "2567    2567  [*]Oc1ccc(Oc2ccc(Oc3cccc([*])n3)cc2)cc1      Egc  4.1433\n",
      "1592    1592    [*]CCC(C)(C)CC(C)CNC(=O)CCCCC(=O)N[*]      Egc  5.8095\n",
      "5601    5601       [*]CC(C=C1)=CC=C1C(C=C2)=CC=C2O[*]       nc  1.8665\n"
     ]
    }
   ],
   "source": [
    "train_df,test_df = train_test_split(df,random_state = 104,test_size = 0.25,shuffle = True)\n",
    "print('train_df : ')\n",
    "print(train_df.head())\n",
    "print('test_df : ')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74527291",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74527291",
    "outputId": "c8d9ca2c-6cfb-4375-b9ef-564582c5f09f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <rdkit.Chem.rdchem.Mol object at 0x7f873772e430>\n",
       "1    <rdkit.Chem.rdchem.Mol object at 0x7f873772e3c0>\n",
       "2    <rdkit.Chem.rdchem.Mol object at 0x7f873772e580>\n",
       "3    <rdkit.Chem.rdchem.Mol object at 0x7f873772e510>\n",
       "4    <rdkit.Chem.rdchem.Mol object at 0x7f873772e660>\n",
       "5    <rdkit.Chem.rdchem.Mol object at 0x7f873772e6d0>\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MOL = pd.DataFrame(['C(OC(=O)C(C[*])[*])C(F)(F)F',\n",
    "# 'O(C(=O)C(C[*])[*])CCOC(C(F)(F)F)C(F)(F)F',\n",
    "# 'O(C(=O)C(C[*])[*])CCOC(C(F)(F)F)(C(F)(F)F)C(F)(F)F',\n",
    "# 'O(C(=O)C(C[*])[*])CCOC',\n",
    "# 'O(C(=O)C(C[*])[*])CCO[H]',\n",
    "# 'O(C(=O)C(C[*])[*])CC[S](C)=O'])[0].apply(Chem.MolFromSmiles)\n",
    "\n",
    "#MOL = smiles.apply(Chem.MolFromSmiles)\n",
    "#MOL = pd.DataFrame(['[*]CC([*])C','[*]CC([*])F','[*]CC([*])(F)F','[*]CC([*])(F)F'])[0].apply(Chem.MolFromSmiles)\n",
    "MOL = pd.DataFrame(['[*]CC([*])C',\n",
    "                    '[*]CC([*])F',\n",
    "                    '[*]CC([*])(F)F',\n",
    "                    '[*]CC([*])(F)F',\n",
    "                    '[*]C(F)C([*])(F)F',\n",
    "                    '[*]CCC(F)(F)C([*])(F)F'])[0].apply(Chem.MolFromSmiles)\n",
    "MOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4fd001",
   "metadata": {
    "id": "9e4fd001"
   },
   "outputs": [],
   "source": [
    "#all_smile = pd.DataFrame(smiles)\n",
    "#Mol = all_smile.squeeze()\n",
    "MOL = smiles.apply(Chem.MolFromSmiles)\n",
    "\n",
    "#print(MOL)\n",
    "# MOL = Mol.apply(Chem.MolFromSmiles)\n",
    "# type(Mol)\n",
    "#df['smiles_mol'] = df['smiles'].apply(Chem.MolFromSmiles)\n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46bf8484",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46bf8484",
    "outputId": "130cad81-d3d4-47ce-a87a-113c549e2616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       {755337623: 1, 1302073591: 1, 1307459754: 1, 1...\n",
      "1       {188605169: 1, 485458970: 1, 882399112: 1, 130...\n",
      "2       {71879828: 1, 485463469: 2, 882399112: 2, 1302...\n",
      "3       {485458970: 1, 485463469: 2, 882399112: 3, 130...\n",
      "4       {485463469: 4, 882399112: 4, 1302073591: 1, 13...\n",
      "                              ...                        \n",
      "6260    {412198813: 1, 485463469: 4, 666309351: 2, 712...\n",
      "6261    {117706561: 1, 485463469: 4, 533204632: 1, 805...\n",
      "6262    {485463469: 4, 595323049: 1, 712993388: 1, 864...\n",
      "6263    {352073271: 1, 485463469: 4, 853890546: 1, 854...\n",
      "6264    {18104817: 1, 280572389: 1, 485463469: 4, 5332...\n",
      "Name: smiles, Length: 6265, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#fp_1 = df['smiles_mol'].apply(lambda m: AllChem.GetMorganFingerprint(m, radius=3))\n",
    "fp_1 = MOL.apply(lambda m: AllChem.GetMorganFingerprint(m, radius=3))\n",
    "\n",
    "fp_1_n = fp_1.apply(lambda m: m.GetNonzeroElements())\n",
    "print(fp_1_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656590d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "656590d9",
    "outputId": "20139fd7-1b98-4573-dede-c4a627fa9f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 20691 20692 20693]\n",
      "20694\n"
     ]
    }
   ],
   "source": [
    "# using substructures in dataset-1 to construct a dictionary\n",
    "HashCode = []\n",
    "for i in fp_1_n:\n",
    "    for j in i.keys():\n",
    "        HashCode.append(j)\n",
    "\n",
    "unique_set = set(HashCode)\n",
    "unique_list = list(unique_set)\n",
    "\n",
    "\n",
    "Corr_df = pd.DataFrame(unique_list).reset_index()\n",
    "# print(Corr_df)\n",
    "# print(type(Corr_df))\n",
    "print(Corr_df['index'].values)\n",
    "#unique_list\n",
    "print(len(unique_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e7a6b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02e7a6b8",
    "outputId": "398add8e-9660-41ec-e9f3-3d90f5413c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#construct dataset-1 input\n",
    "MY_finger = []\n",
    "for polymer in fp_1_n:\n",
    "    my_finger = [0] *len(unique_list)\n",
    "    for key in polymer.keys():\n",
    "        index = Corr_df[Corr_df[0] == key]['index'].values[0]\n",
    "        my_finger[index] = polymer[key]\n",
    "    MY_finger.append(my_finger)\n",
    "\n",
    "MY_finger_dataset = pd.DataFrame(MY_finger)  \n",
    "print(type(MY_finger_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8c4406d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "f8c4406d",
    "outputId": "addfb39b-e6e2-4bb9-8e94-407ac0941343",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20684</th>\n",
       "      <th>20685</th>\n",
       "      <th>20686</th>\n",
       "      <th>20687</th>\n",
       "      <th>20688</th>\n",
       "      <th>20689</th>\n",
       "      <th>20690</th>\n",
       "      <th>20691</th>\n",
       "      <th>20692</th>\n",
       "      <th>20693</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6265 rows × 20694 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0         0      0      0      0      0      0      0      0      0      0   \n",
       "1         0      0      0      0      0      0      0      0      0      0   \n",
       "2         0      0      0      0      0      0      0      0      0      0   \n",
       "3         0      0      0      0      0      0      0      0      0      0   \n",
       "4         0      0      0      0      0      0      0      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "6260      0      0      0      0      0      0      0      0      0      0   \n",
       "6261      0      0      0      0      0      0      0      0      0      0   \n",
       "6262      0      0      0      0      0      0      0      0      0      0   \n",
       "6263      0      0      0      0      0      0      0      0      0      0   \n",
       "6264      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      ...  20684  20685  20686  20687  20688  20689  20690  20691  20692  \\\n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "6260  ...      0      0      0      0      0      0      0      0      0   \n",
       "6261  ...      0      0      0      0      0      0      0      0      0   \n",
       "6262  ...      0      0      0      0      0      0      0      0      0   \n",
       "6263  ...      0      0      0      0      0      0      0      0      0   \n",
       "6264  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      20693  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "6260      0  \n",
       "6261      0  \n",
       "6262      0  \n",
       "6263      0  \n",
       "6264      0  \n",
       "\n",
       "[6265 rows x 20694 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_finger_dataset\n",
    "#print(MY_finger_dataset.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "PWkpTYvVOVeq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWkpTYvVOVeq",
    "outputId": "6f249909-2a6e-4922-88a5-8ae8f1fe31d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(MY_finger_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d388432",
   "metadata": {
    "id": "5d388432"
   },
   "outputs": [],
   "source": [
    "MY_finger_dataset.to_csv('MY_finger_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c834d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72c834d8",
    "outputId": "43897ba2-6d25-48b6-d0a0-4be1bc546077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# filter input into the most popular 124 substructures\n",
    "Zero_Sum = (MY_finger_dataset == 0).astype(int).sum()\n",
    "NumberOfZero = 6\n",
    "print(len(Zero_Sum[Zero_Sum < NumberOfZero]))\n",
    "X = MY_finger_dataset[Zero_Sum[Zero_Sum < NumberOfZero].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec581d54",
   "metadata": {
    "id": "ec581d54"
   },
   "outputs": [],
   "source": [
    "# Then, import the necessary modules\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Generate random task labels \n",
    "labels = np.random.randint(0, 2, size=MY_finger_dataset.shape[0])\n",
    "\n",
    "# # Load the task labels from the CSV file\n",
    "# y = np.loadtxt(\"task_labels.csv\", delimiter=\",\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(MY_finger_dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "QxvUxqdTA5Mv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxvUxqdTA5Mv",
    "outputId": "ba07c5c5-d1c3-494a-fcee-88ad1d951df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "# Save the task labels to a CSV file\n",
    "np.savetxt(\"task_labels.csv\", labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45088883",
   "metadata": {
    "id": "45088883"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/yuyang/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "# param_svm = {'kernel': ('linear', 'rbf','poly'),\n",
    "#               'C':[1.5, 10],\n",
    "#               'gamma': [1e-7, 1e-4],\n",
    "#               'epsilon':[0.1,0.2,0.5,0.3]}\n",
    "param_svm = {\n",
    "              'C':[1, 10],\n",
    "              'gamma': [0.1,1,10],\n",
    "              }\n",
    "svr = SVR()\n",
    "random_svm = RandomizedSearchCV(svr,param_svm, cv= 5,scoring='accuracy')\n",
    "random_svm.fit(X_train,y_train)\n",
    "best_regressor_svm = random_svm.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ded4ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32ded4ce",
    "outputId": "b16f3fd0-7b59-4e5e-91db-f26c32c93483"
   },
   "outputs": [],
   "source": [
    "y_pred_svm = best_regressor_svm.predict(X_test)\n",
    "y_pred_svm_mean = np.mean(y_pred_svm)\n",
    "print(y_pred_svm_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf80fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54cf80fc",
    "outputId": "380b2074-e60d-4b9c-e0ca-02f45a0057ba"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Compute Root Mean Square Error(RMSE)\n",
    "\n",
    "Rmse_pred_svm = np.sqrt(mean_squared_error(y_test,y_pred_svm))\n",
    "\n",
    "print(Rmse_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48fc4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a48fc4f",
    "outputId": "455595fa-94b9-42d5-d0de-a8cb9629a57e"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 0.01. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: mean_squared_error() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the kernel for the Gaussian process\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "\n",
    "# Create the Gaussian process regressor object\n",
    "gp = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# Define the parameter grid for the search\n",
    "param_grid = {\n",
    "    \"kernel__k1__constant_value\": [1e-1, 1, 1e1, 1e2],\n",
    "    \"kernel__k2__length_scale\": [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "Random_gpr = RandomizedSearchCV(\n",
    "    gp, param_grid, cv=5, n_iter=10, scoring=mean_squared_error, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the data using the fingerprint vectors as input\n",
    "Random_gpr.fit(X_train,y_train)\n",
    "\n",
    "best_regressor_gpr = random_gpr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd56a1b",
   "metadata": {
    "id": "6fd56a1b"
   },
   "outputs": [],
   "source": [
    "# Use the model to make predictions\n",
    "y_pred_gpr = best_regressor_gpr.predict(X_test)\n",
    "y_pred_gpr_mean = np.mean(y_pred_gpr)\n",
    "print(y_pred_gpr_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfef04",
   "metadata": {
    "id": "86cfef04"
   },
   "outputs": [],
   "source": [
    "# Compute Root Mean Square Error(RMSE)\n",
    "\n",
    "Rmse_pred_gpr = np.sqrt(mean_squared_error(y_test,y_pred_gpr))\n",
    "\n",
    "print(Rmse_pred_gpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8263a5c",
   "metadata": {
    "id": "d8263a5c"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Create the multi-task learning model\n",
    "model = MultiOutputRegressor()\n",
    "\n",
    "# Use RandomizedSearchCV to tune the hyperparameters\n",
    "param_distributions = {'n_estimators': [10, 50, 100, 200],\n",
    "                       'max_depth': [None, 2, 4, 6, 8]}\n",
    "Random_multi = RandomizedSearchCV(model, param_distributions, n_iter=10, cv=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "Random_multi.fit(X_train, y_train)\n",
    "\n",
    "best_regressor_multi = random_multi.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff397f",
   "metadata": {
    "id": "23ff397f"
   },
   "outputs": [],
   "source": [
    "# Use the model to make predictions\n",
    "y_pred_multi = best_regressor_multi.predict(fingerprint_vectors)\n",
    "y_pred_multi_mean = np.mean(y_pred_gpr)\n",
    "print(y_pred_multi_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932410ab",
   "metadata": {
    "id": "932410ab"
   },
   "outputs": [],
   "source": [
    "# Compute Root Mean Square Error(RMSE)\n",
    "\n",
    "Rmse_pred_multi = np.sqrt(mean_squared_error(y_test,y_pred_multi))\n",
    "\n",
    "print(Rmse_pred_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e201a4",
   "metadata": {
    "id": "c0e201a4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load the numerical vector representation of the Morgan Fingerprint and the labels for each task\n",
    "X = np.load(\"fingerprint_data.npy\")\n",
    "y = np.load(\"task_labels.npy\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(y.shape[1], activation='linear')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define the parameter distribution for the RandomizedSearchCV\n",
    "param_distributions = {'batch_size': [16, 32, 64, 128],\n",
    "                       'epochs': [10, 20, 50, 100]}\n",
    "\n",
    "# Use RandomizedSearchCV to tune the hyperparameters of the neural network model\n",
    "random_search = RandomizedSearchCV(model, param_distributions, cv=5, n_iter=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = random_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bv7uM5JBRGj2",
   "metadata": {
    "id": "Bv7uM5JBRGj2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load the numerical vector representation of the Morgan Fingerprint and the labels for each task\n",
    "X = np.load(\"fingerprint_data.npy\")\n",
    "y = np.load(\"task_labels.npy\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the Random Forest regressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define the parameter distribution for the RandomizedSearchCV\n",
    "param_distributions = {'n_estimators': [10, 50, 100, 200, 500],\n",
    "                       'max_depth': [2, 5, 10, 20, None]}\n",
    "\n",
    "# Use RandomizedSearchCV to tune the hyperparameters of the Random Forest regressor\n",
    "random_search = RandomizedSearchCV(rf, param_distributions, cv=5, n_iter=10)\n",
    "\n",
    "# Fit the Random Forest regressor to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = random_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gV07mb5FRrHV",
   "metadata": {
    "id": "gV07mb5FRrHV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load the numerical vector representation of the Morgan Fingerprint and the labels for each task\n",
    "X = np.load(\"fingerprint_data.npy\")\n",
    "y = np.load(\"task_labels.npy\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Convert the data to the format required by XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgboost = xgb.XGBRegressor()\n",
    "\n",
    "# Define the parameter distribution for the RandomizedSearchCV\n",
    "param_distributions = {'n_estimators': [10, 50, 100, 200, 500],\n",
    "                       'max_depth': [2, 5, 10, 20]}\n",
    "\n",
    "# Use RandomizedSearchCV to tune the hyperparameters of the XGBoost model\n",
    "random_search = RandomizedSearchCV(xgboost, param_distributions, cv=5, n_iter=10)\n",
    "\n",
    "# Fit the XGBoost model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = random_search.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
